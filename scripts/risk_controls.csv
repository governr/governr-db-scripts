Risk ID,Asset Type,Risk Name,Score 0 (Gap),Score 25 (Weak),Score 50 (Baseline),Score 75 (Robust),Score 100 (Compliant)
DST-Q01,Dataset,Data Poisoning,No lineage or verification. Untracked data modifications allow malicious samples.,Manual tracking. Logs of primary sources; no systematic integrity scanning.,Automated internal lineage. Basic provenance tracking via Apache Atlas.,Validated integrity. Provenance tracked upstream; hashes validated via DataHub.,Leading detection. Real-time adversarial scans using ART or CleanLab.
DST-Q02,Dataset,PII Leakage,Raw PII exposed. Discovery or masking is absent; model memorises sensitive records.,Manual redaction. Ad-hoc removal of high-profile fields; no automation.,Automated scanners. Pipeline scanners like Nabu Casa flag some data.,Automated classification. Data classified/quarantined via Microsoft Information Protection.,Real-time DLP. Validated tokenisation and privacy layers using Presidio or Opacus.
DST-Q03,Dataset,Data Drift,No monitoring. Silent distribution shifts cause model performance degradation.,Irregular checks. Ad-hoc manual verification of data distribution.,Schema validation. Freshness and schema checks via Data Quality DBT.,Continuous monitoring. Drift alerts and tracking implemented via Evidently AI.,Automated gating. Drift-driven circuit breakers using WhyLabs and Great Expectations.
DST-Q04,Dataset,Secrets Exposure,Cleartext credentials. API keys or credentials embedded in training/RAG data.,Manual search. Ad-hoc removal of keys upon discovery; high risk of oversight.,Automated scanning. Keyword scanners in pipelines for common secret formats.,Ingestion masking. Secrets automatically identified/redacted via Microsoft Information Protection.,Vault integration. Automated revocation and sanitisation via HashiCorp Vault.
DST-Q05,Dataset,Supply Chain Poisoning,No 3rd party verification. Ingestion from public repos without technical checks.,Reputation reliance. Trusting vendor claims without independent verification.,Periodic audits. Manual auditing of third-party data samples quarterly.,Automated 3rd party lineage. Checksum validation and source tracking via DataHub.,Real-time integrity. Continuous monitoring of external repositories via ART tools.
DST-Q06,Dataset,Over-Retention,Indefinite storage. Long-term storage expands the breach blast radius.,Manual deletion. Data purged manually following project closure; inconsistent.,Policy defined. Retention periods defined by data class; manually enforced.,Automated purging. Cron-based purging and PostgreSQL partitioning implemented.,Lifecycle-driven. Automated policy-driven deletion via S3 lifecycle policies or Airflow.
DST-Q07,Dataset,Lineage Gaps,No modification tracking. Incident investigations fail due to lack of audit trails.,Manual spreadsheets. Major versions tracked in shared documents.,Final set versioning. Versioning applied only to final production training sets.,Full provenance. Audit trails for all modifications tracked via Apache Atlas.,"Metadata management. Real-time, comprehensive lineage mapping via DataHub."
DST-Q08,Dataset,Quality Degradation,No validation. Garbage-in-garbage-out leads to systematic decision errors.,Ad-hoc samples. Visual inspection of samples before training.,Automated checks. Freshness and schema checks run at pipeline ingress.,Continuous QA. End-to-end signal quality validation via Monte Carlo.,CI/CD quality gating. Automated pipeline halts for quality failures via Great Expectations.
DST-Q09,Dataset,Membership Inference,No privacy controls. Attackers can determine if specific records were in training set.,Basic masking. Standard identification of primary keys only.,Statistical de-identification. Manual application of Faker library for anonymisation.,Advanced pseudonymisation. Validated de-identification tested for reconstruction.,DP Integration. Differential privacy integrated into training via Opacus.
DST-Q10,Dataset,Synthetic Data Failure,No quality testing. Poor synthetic data mimics real poisoning effects.,Visual inspection. Samples reviewed manually for realism.,Statistical comparison. Automated comparison between real and synthetic sets.,Poison detection. Poison indicators scanned in all synthetic sets pre-usage.,Adversarial gating. Synthetic quality gating via Adversarial Robustness Toolbox (ART).
MDL-Q01,Model,Prompt Injection,Direct input processing. No filtering or safety evaluations; direct user input accepted.,Keyword filtering. Basic keyword-based blacklists for sensitive terms.,Pre-deployment evals. Safety evaluations conducted before deployment using HELM.,Multi-layer filters. Output filtering with L0/L1 guardrails.,Real-time protection. Continuous protection using Lakera Gandalf or NeMo Guardrails.
MDL-Q02,Model,Model Extraction,Unrestricted access. No query monitoring or extraction detection.,Standard throttling. Basic rate limiting enforced at the API gateway.,Pattern monitoring. Monitoring for high-frequency extraction patterns.,Embedded signals. Detectable watermarks embedded in model outputs.,Verifiable signatures. Hidden signals detectable by verifiers using Tree-Ring.
MDL-Q03,Model,Adversarial Evasion,No robustness testing. Vulnerable to misclassification from crafted inputs.,Input sanitisation. Basic sanitisation of inputs to remove malicious characters.,Robustness benchmarks. Adversarial benchmarks run pre-deployment using Robustness Gym.,Augmented training. Training sets augmented with adversarial examples.,Certified defences. Use of certified defences and Adversarial Robustness Toolbox (ART).
MDL-Q04,Model,Jailbreaking,No safety gates. Model can generate harmful content without restriction.,Base model safety. Reliance on the base provider's internal safety tuning.,Manual red-teaming. Irregular manual red-teaming exercises pre-release.,Automated moderation. Quarterly safety benchmarks using HELM or Garak.,Continuous testing. External pentesting with Bugcrowd or Synack and real-time updates.
MDL-Q05,Model,Model Inversion,No training privacy. Training data easily reconstructed from model outputs.,Basic masking. Standard identification and masking of primary identifiers.,Reconstruction tests. Periodic manual testing for data reconstruction.,Validated redaction. Automated masking at ingestion with SDV or Faker.,Differential privacy. Privacy-preserving training implemented via Opacus.
MDL-Q06,Model,Overconfidence,No confidence signals. Predictions lack reliable uncertainty measures.,Manual sanity checks. User-driven identification of overconfident errors.,Temperature scaling. Calibration techniques applied to normalise output probabilities.,Uncertainty heads. Implementation of Bayesian heads or MC dropout for estimation.,Automated fallback. Low-confidence scores trigger human review via n8n or feature flags.
MDL-Q07,Model,Bias Amplification,No bias checks. Societal biases in training data are amplified unchecked.,Manual audits. Occasional manual reviews for demographic bias.,Safety benchmarks. Standard bias benchmarks run as part of HELM evaluations.,Automated monitoring. Continuous monitoring of outputs for biased patterns.,Real-time mitigation. Dynamic output guardrails using Perspective API.
MDL-Q08,Model,Backdoor Triggers,No scanning. Hidden triggers allow targeted malicious behaviour.,Provider reliance. Reliance on base-model provider safety claims.,Data scanning. Periodic scanning of fine-tuning data for statistical anomalies.,Outlier detection. Pre-training outlier detection using Alibi Detect or ART.,Full sanitisation. Training loss monitoring and cryptographic validation of data.
MDL-Q09,Model,Performance Drift,No observability. Silent degradation goes unnoticed after deployment.,User reporting. Ad-hoc feedback loops for performance issues.,Metric monitoring. Automated tracking of latency and error rates.,Continuous tracing. Decision observability implemented via Langfuse or Phoenix.,Automated failover. Drift detection triggers failover to Challenger Models via FastAPI.
MDL-Q10,Model,Watermark Removal,No traceability. Traceability markers are absent or easily removed.,Simple text markers. Basic text-based watermarking easily bypassed.,Standard signatures. Standard watermark signatures without verification tools.,Tree-Ring Signals. Advanced hidden signals embedded in generations.,"Robust watermarks. Undetectable, robust watermarks verifiable via OpenAI Watermarking tools."
AGT-Q01,Agent,Tool Misuse,Agents have full access to all tools without limits.,Static access control; no runtime policy checks.,Role-based tool access assigned per agent persona.,Runtime policy checks for action approval using Open Policy Agent (OPA) or Casbin.,Context-aware execution with dynamic tool scoping via Pydantic AI validators.
AGT-Q02,Agent,Goal Misalignment,Agents pursue unintended or unbounded objectives.,Manual monitoring of agent logs for goal drift.,Strictly bounded prompts with termination criteria.,Scoped objectives and iteration limits defined via LangChain callbacks.,Strict outcome validation using Pydantic output schemas to prevent drift.
AGT-Q03,Agent,Prompt Injection,Malicious context directly hijacks agent reasoning.,Basic input sanitisation for known attack strings.,Policy-as-code engines used for plan approval pre-execution.,Multi-layer guardrails on reasoning paths via Open Policy Agent (OPA).,Zero-trust context architecture using Lakera Guard to isolate agent reasoning.
AGT-Q04,Agent,Privilege Escalation,Agent operates as root or with administrative privileges.,Hardcoded credentials; broad access across systems.,Least-privilege permissions; limited to non-destructive tools.,Dynamic permission scoping based on task context via SpiffWorkflow.,Just-in-time tokens and restricted session-based privileges via Temporal.io.
AGT-Q05,Agent,Shared State Poisoning,Universal memory shared across all agent cohorts.,Manual intervention to clear session data periodically.,Per-session memory isolation implemented.,Isolated vector stores using Pinecone namespaces to prevent contamination.,Cryptographic tenant isolation in memory via PGVector per-tenant stores.
AGT-Q06,Agent,Infinite Loops,No monitoring for recursive tool calling.,Manual stop implemented when resource costs spike.,Iteration limits enforced at the orchestrator level.,Recursion limits and loop detection callbacks via LangChain.,Automated circuit breakers for recursive patterns via Resilience4j.
AGT-Q07,Agent,Data Exfiltration,Agents send sensitive data to unverified endpoints.,Basic egress filtering on known tool endpoints.,Static DLP scanning on common exfiltration paths.,Inline redaction of PII/secrets in agent tool outputs via Presidio.,Real-time exfiltration blocking using Nightfall AI or Lakera Guard.
AGT-Q08,Agent,Over-Automation,Fully autonomous execution of high-risk financial actions.,Post-execution alerts; no ability to halt actions.,Manual flagging of critical tasks for potential review.,Risk-scored task classification and approval queues via n8n nodes.,Hard human-in-the-loop gating for all financial tasks via LangGraph.
AGT-Q09,Agent,Context Overflow,Excessive context leading to model hallucinations.,Manual prompt engineering to reduce context window usage.,Hard token limits enforced on context windows.,Dynamic context truncation and window management via LangChain.,Intelligent summarisation and schema validation via Pydantic.
AGT-Q10,Agent,Tool Chain Abuse,Chaining benign tools for malicious outcomes.,Manual review of common tool-chain runbooks.,Policy-as-code approval for common sequences.,Risk-gated orchestration using Airflow sensors to score impact.,Automated state transition checks via Temporal workflows.
SYS-Q01,System,Orchestration Hijack,Malicious signals trigger erroneous workflows without validation.,Manual review of a sample of input signals.,Signals validated against fixed schemas via Pydantic.,Multi-source validation with anomaly scoring via Great Expectations.,Trust scoring and historical accuracy weighting via Bayesian trust models.
SYS-Q02,System,Compliance Violations,AI recommendations violate business rules or regulatory requirements.,Ad-hoc manual audits of AI-generated decisions.,Periodic audits and documented governance policies.,Output validation against hardcoded rules using Easy Rules or Drools.,Real-time enforcement via automated governance platforms like Drata or Vanta.
SYS-Q03,System,Shadow AI,Unauthorised/unknown AI systems operating in the environment.,Manual inventory of AI assets updated on an irregular basis.,Discovery scans on network traffic to identify AI endpoints.,Automated discovery and integration monitoring via Prometheus.,Real-time blocking and full observability via ELK stack or ClickHouse.
SYS-Q04,System,Decision Drift,Silent degradation of AI recommendations over time.,User-reported errors only; no proactive tracking.,Automated tracking of high-level performance metrics.,Continuous drift and latency monitoring via Langfuse or Phoenix.,Automated retuning or failover triggered by Great Expectations quality gates.
SYS-Q05,System,Integration Abuse,Compromised AI systems affect downstream production systems.,No isolation between AI and downstream infra.,Basic egress filtering and rate limiting applied.,Integrated DLP and downstream policy checks using Nightfall AI.,Zero-trust integration and per-action auth via OPA for Terraform or Sentinel.
SYS-Q06,System,Audit Gaps,Inability to reconstruct decisions during incident investigation.,No logging of AI decisions or system signals.,Basic unstructured text logs of system activity.,Structured logging of all decision paths via ELK stack.,"Tamper-proof, replayable traces stored in ClickHouse."
SYS-Q07,System,Resource Exhaustion,"AI consumes disproportionate infra, causing availability failures.",No limits on AI compute or API consumption.,Manual monitoring of infrastructure costs.,Static per-asset quotas enforced via Redis-backed limits.,Predictive scaling and real-time throttling via FastAPI-Limiter.
SYS-Q08,System,False Automation,Over-automation causing operational chaos.,Fully autonomous workflows with no human gates.,Static approval gates for all workflows regardless of risk.,Risk-weighted gating and Airflow sensors for high-impact tasks.,Hard human-in-the-loop sign-off via n8n or Zapier Enterprise.
SYS-Q09,System,Vendor Lock-in,Single AI vendor creating strategic switching costs.,Deep integration with a single proprietary model/API.,Standardised API usage to allow for model swapping.,Abstraction layers and multi-vendor threat modelling via Threat Dragon.,"Fully portable, model-agnostic architecture validated through STRIDE workshops."
SYS-Q10,System,Ethical Drift,Gradual erosion of ethical standards in AI outcomes.,No ethical evaluation or impact monitoring.,Occasional manual ethical reviews of AI behavior.,Automated ethical patterns monitored via Langfuse observability.,Real-time ethical guardrails and compliance mapping via Drata or Vanta.
API-Q01,API,API Key Abuse,Static keys with no rotation or MFA.,Long-lived keys with manual tracking.,Key rotation policy in place with vault storage.,Automated rotation via HashiCorp Vault or AWS Secrets Manager.,"Short-lived JWTs and secure auth via OAuth2, Keycloak, or Auth0."
API-Q02,API,Rate Limit Bypass,No throttling; high-volume extraction possible.,Static global limits applied at the gateway.,Per-key and global rate limits implemented.,Behavioural detection for anomaly query volumes via Splunk UEBA.,ML-based baselines and real-time adaptive throttling.
API-Q03,API,Input Injection,No backend validation; malicious payloads accepted.,Basic keyword-based input sanitisation.,Backend validation logic embedded in the API layer.,Inline DLP scanning before context release via Nightfall AI or Presidio.,Zero-trust ingress with real-time payload inspection using Lakera Guard.
API-Q04,API,Over-Permissive Scopes,Universal tokens allowing all operations.,Broad role-based access; high privilege escalation risk.,Granular RBAC scoping APIs by asset type and action.,FastAPI-integrated middleware using Casbin for fine-grained control.,Dynamic scope assignment and just-in-time (JIT) API permissions.
API-Q05,API,Verbose Errors,Full stack traces leaked in error responses.,Generic error messages with some technical detail.,Internal codes mapped to external IDs; no secrets leaked.,Automated redaction of error payloads via Presidio.,Fully sanitized/encrypted logs with no prompt or secret leakage.
API-Q06,API,No Client Isolation,Shared keys for all tenants; multi-tenant compromise risk.,Static client buckets; no strict isolation.,Token-based identification of unique clients.,RBAC-enforced isolation by action and asset using Casbin.,Cryptographic multi-tenant isolation with per-client routing.
API-Q07,API,Missing Quotas,Unbounded compute/token consumption.,Manual billing alerts triggered after thresholds.,Static monthly quotas assigned per API key.,Tiered quotas enforced via Redis-backed limiting.,Real-time token gating and automated resource circuit breakers.
API-Q08,API,Weak Rate Limiting,No protection against service degradation.,Basic IP-based rate limiting.,Standard per-key rate limiting implementation.,Distributed limiting and burst protection using FastAPI-Limiter.,Global protective gates with Redis-backed persistence.
API-Q09,API,No Logging,No traffic logs; blind monitoring of abuse.,Standard access logs; unstructured text.,Structured decision and action logs.,Tamper-proof traces stored in ELK stack or ClickHouse.,Full replayable traces for all orchestration paths.
API-Q10,API,Legacy Auth,Basic auth or keys without rotation.,Static keys with irregular manual updates.,Standard OAuth2 implementation.,Vault-integrated rotation with defined policies.,MFA enabled with short-lived JWTs for all model endpoints.
MCP-Q01,MCP Server,Rogue MCP Servers,Unverified/unknown servers receive agent context.,Manual checking of endpoints against static lists.,GitOps change control for configurations.,Whitelist of approved endpoints via Flux.,Curated registry with signature validation in PostgreSQL via ArgoCD.
MCP-Q02,MCP Server,Context Oversharing,Full agent context shared with all tools.,Manual truncation of prompts before calls.,Static token length limits enforced.,Need-to-know truncation via Pydantic validators.,Inline PII masking and context minimisation via Presidio integration.
MCP-Q03,MCP Server,Unencrypted MCP,Cleartext traffic; vulnerable to MITM attacks.,Standard SSL/TLS without certificate validation.,Enforced TLS 1.2+ for all tool communications.,Certificate pinning implemented via FastAPI SSL.,Mandatory mTLS with cert-manager for all tool sessions.
MCP-Q04,MCP Server,Tool Injection,Malicious tools executing arbitrary code (RCE).,Static list of allowed tools reviewed manually.,Registry-based validation of tool signatures.,Runtime verification of tool integrity via PostgreSQL registry.,Sandboxed tool execution with cryptographically signed whitelists.
MCP-Q05,MCP Server,MCP Chain Abuse,Tool chaining leads to unintended multi-hop attacks.,Manual review of common tool-chain runbooks.,Policy-as-code approval for common tool sequences.,Enforced runtime policy checks via Casbin.,Zero-trust action approval and reasoning isolation via Open Policy Agent (OPA).
MCP-Q06,MCP Server,No MCP Registry,Shadow MCP deployments; untracked attack surface.,Ad-hoc tracking of servers in documentation.,Automated discovery scans for active endpoints.,Centralised PostgreSQL registry for all approved assets.,Registry-enforced gating integrated with ArgoCD for all deployments.
MCP-Q07,MCP Server,Weak Tool Auth,Tools callable without agent context validation.,Reliance on basic API keys or shared secrets.,Role-based tool access implemented.,Context-aware tool authentication via FastAPI SSL.,Just-in-time (JIT) tool tokens and mTLS authentication.
MCP-Q08,MCP Server,Egress Blind Spots,Undetected data exfiltration via tool endpoints.,Basic proxy logging for high-level traffic.,Periodic manual review of egress traffic logs.,Real-time traffic anomaly detection via Cloudflare Gateway.,Inline DLP scanning and blocking via Zscaler.
MCP-Q09,MCP Server,Config Drift,MCP configs diverging from approved secure states.,Manual configuration updates and ad-hoc audits.,Periodic automated schema and freshness checks.,GitOps-driven configuration management via Flux.,Automated remediation of drift via ArgoCD and Kubernetes operators.
MCP-Q10,MCP Server,Shared MCP Abuse,One compromised MCP affects multiple agents.,Universal shared instances for all agents.,Static isolation of tool instances by agent cohort.,Per-agent namespaces and isolation via PostgreSQL.,Cryptographic isolation of per-task tool contexts and mTLS.
